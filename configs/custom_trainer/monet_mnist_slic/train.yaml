trainer_name: base_trainer
version: 1.0
dataloader_type: geometric
input_key: 
  - graph

main_config: &main
  seed: 42
  metrics:
    - type: sklearn_acc
      params:
        normalize: True
  device:
    name: cuda

train: &train
  <<: *main
  # Can add the max_epochs vs max_steps functionality
  label_type: logit
  append_text: train
  max_epochs: 10
  loader_params:
    batch_size: 32
    num_workers: 2
    shuffle: true
  save_after_epoch: true
  optimizer:
    type: adam_w
    params:
      lr: 1e-5
      betas: [0.9, 0.998]
      eps: 1e-8

  scheduler: null

  criterion:
    type: CrossEntropyLoss
    params: null

  save_on: ##Best Model/Final Model Saving
    score: sklearn_acc
    desired: min
    best_path: "${..checkpoint.checkpoint_dir}train/best_${..log.log_label}.pth" ## Number should be same as log_label
    final_path: "${..checkpoint.checkpoint_dir}train/final_${..log.log_label}.pth" ## Number should be same as log_label

  checkpoint:
    checkpoint_dir: "./ckpts/base_trainer/" #For checkpoint saving after every epoch.

  log_and_val_interval: 500 ## Set to null if using different val and log intervals, Overrides log_interval nd val_interval

  val_interval: 500 # Global steps
  log:
    log_interval: 500 # Global Steps
    logger_params:
      model: monet
      trainer: base_trainer
      comment: "MoNet trained on MNIST data."
      log_dir: "./logs/monet_mnist_slic/"
    log_label: 1
    vals:
      loss: True
      metrics: True
      hparams: null

val:
  <<: *main
  append_text: val
  max_steps: null
  loader_params:
    batch_size: 32
    num_workers: 2
    shuffle: false
